{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Assignment_NLP_LukaszPszonak.ipynb","provenance":[{"file_id":"1xUjvWDbULs_xHZBiujpBhaz1tA6cD2B4","timestamp":1610556975475}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"qse4rXu-yndk"},"source":[""]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iAbK_E0wx9hO","executionInfo":{"status":"ok","timestamp":1610652220570,"user_tz":-60,"elapsed":3730,"user":{"displayName":"Łukasz Pszonak","photoUrl":"","userId":"11546911228613384550"}},"outputId":"1cbeea1c-3ee6-42e9-cd29-3abf032f54db"},"source":["!pip install PyDrive\r\n","from pydrive.auth import GoogleAuth\r\n","from pydrive.drive import GoogleDrive\r\n","from google.colab import auth\r\n","from oauth2client.client import GoogleCredentials\r\n"," \r\n","auth.authenticate_user()\r\n","gauth = GoogleAuth()\r\n","gauth.credentials = GoogleCredentials.get_application_default()\r\n","drive = GoogleDrive(gauth)\r\n","\r\n"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: PyDrive in /usr/local/lib/python3.6/dist-packages (1.3.1)\n","Requirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (1.7.12)\n","Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (4.1.3)\n","Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (3.13)\n","Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (0.0.4)\n","Requirement already satisfied: httplib2<1dev,>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (0.17.4)\n","Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (3.0.1)\n","Requirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.15.0)\n","Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.17.2)\n","Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.2.8)\n","Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (4.6)\n","Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.4.8)\n","Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.2->PyDrive) (51.1.1)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.2->PyDrive) (4.2.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2J8qct_pu5cm","executionInfo":{"status":"ok","timestamp":1610652223376,"user_tz":-60,"elapsed":6529,"user":{"displayName":"Łukasz Pszonak","photoUrl":"","userId":"11546911228613384550"}}},"source":["downloaded = drive.CreateFile({'id':\"1ZxhzlSTrEbO4GVaGrkqawfeoeFDmPvWl\"})  \r\n","downloaded.GetContentFile('intents.json')     \r\n","#if choosing a different dataset, modify the above file location and name"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UX-IHmDnKzdp","executionInfo":{"status":"ok","timestamp":1610652224487,"user_tz":-60,"elapsed":7629,"user":{"displayName":"Łukasz Pszonak","photoUrl":"","userId":"11546911228613384550"}},"outputId":"2de4898e-6a2b-4852-ba6d-bf7106a18b25"},"source":["#importing relevant libraries\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import random\n","import json\n","import nltk\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","nltk.download('punkt')\n","plt.style.use('classic')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5wYzCl43Aoiq","executionInfo":{"status":"ok","timestamp":1610652224488,"user_tz":-60,"elapsed":7628,"user":{"displayName":"Łukasz Pszonak","photoUrl":"","userId":"11546911228613384550"}}},"source":["%matplotlib inline"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"KmFTdWXBNKhY","executionInfo":{"status":"ok","timestamp":1610652224488,"user_tz":-60,"elapsed":7626,"user":{"displayName":"Łukasz Pszonak","photoUrl":"","userId":"11546911228613384550"}}},"source":["#creating custom functions\n","\n","def tokenize(sentence):\n","    return nltk.word_tokenize(sentence)\n","\n","def stem(word):\n","    return stemmer.stem(word.lower())"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"bj7CewZ2Jg1x","executionInfo":{"status":"ok","timestamp":1610652224489,"user_tz":-60,"elapsed":7624,"user":{"displayName":"Łukasz Pszonak","photoUrl":"","userId":"11546911228613384550"}}},"source":["#stemming using Porter Stemmer model from NLTK library\n","#stemming is the process of training the model to understand all different forms of the same word \n","#for example: play, played, playing\n","\n","\n","from nltk.stem.porter import PorterStemmer\n","stemmer = PorterStemmer()\n"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"ddQDX1wQKYMQ","executionInfo":{"status":"ok","timestamp":1610652224489,"user_tz":-60,"elapsed":7622,"user":{"displayName":"Łukasz Pszonak","photoUrl":"","userId":"11546911228613384550"}}},"source":["#Creating a bag of words - which means splitting each word in the sentences and adding it to an array.\n","#If we have a array of sentences = [\"hello\", \"how\", \"are\", \"you\"] and an array of total words = [\"hi\", \"hello\", \"I\", \"you\", \"bye\", \"thank\", \"cool\"] then its bag of words array will be bog = [ 0 , 1 , 0 , 1 , 0 , 0 , 0].\n","\n","def bag_of_words(tokenized_sentence, words):\n","    \"\"\"\n","    return bag of words array:\n","    1 for each known word that exists in the sentence, 0 otherwise\n","    example:\n","    sentence = [\"hello\", \"how\", \"are\", \"you\"]\n","    words = [\"hi\", \"hello\", \"I\", \"you\", \"bye\", \"thank\", \"cool\"]\n","    bog   = [  0 ,    1 ,    0 ,   1 ,    0 ,    0 ,      0]\n","    \"\"\"\n","    # stem each word\n","    sentence_words = [stem(word) for word in tokenized_sentence]\n","    # initialize bag with 0 for each word\n","    bag = np.zeros(len(words), dtype=np.float32)\n","    for idx, w in enumerate(words):\n","        if w in sentence_words: \n","            bag[idx] = 1\n","\n","    return bag"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"dyslTCEcNm0X","executionInfo":{"status":"ok","timestamp":1610652224490,"user_tz":-60,"elapsed":7622,"user":{"displayName":"Łukasz Pszonak","photoUrl":"","userId":"11546911228613384550"}}},"source":["with open('intents.json', 'r') as f:\n","    intents = json.load(f)\n","#if choosing different dataset, modify the above code"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"-2p39Ghz0pYl","executionInfo":{"status":"ok","timestamp":1610652224491,"user_tz":-60,"elapsed":7621,"user":{"displayName":"Łukasz Pszonak","photoUrl":"","userId":"11546911228613384550"}}},"source":["#The following will unpack the content of the file in order to get the right information\n","#Tokenization below is used to separate all the tags and words into their separate lists\n","\n","all_words = []\n","tags = []\n","xy = []\n","# loop through each sentence in our intents patterns\n","for intent in intents['intents']:\n","    tag = intent['tag']\n","    # add to tag list\n","    tags.append(tag)\n","    for pattern in intent['patterns']:\n","        # tokenize each word in the sentence\n","        w = tokenize(pattern)\n","        # add to our words list\n","        all_words.extend(w)\n","        # add to xy pair\n","        xy.append((w, tag))"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q0DOKFv5OP_Y","executionInfo":{"status":"ok","timestamp":1610652224491,"user_tz":-60,"elapsed":7615,"user":{"displayName":"Łukasz Pszonak","photoUrl":"","userId":"11546911228613384550"}},"outputId":"bdd5fe83-9fc3-4139-9840-8b97d04ed499"},"source":["#This piece of code is responsible for cleaning the data by implementing previously created functions\n","\n","# stem and lower each word\n","ignore_words = ['?', '.', '!'] #For this assignment, I want my chatbot to ignore these.\n","all_words = [stem(w) for w in all_words if w not in ignore_words]\n","# remove duplicates and sort\n","all_words = sorted(set(all_words))\n","tags = sorted(set(tags))\n","\n","print(len(xy), \"patterns\")\n","print(len(tags), \"tags:\", tags)\n","print(len(all_words), \"unique stemmed words:\", all_words)\n"],"execution_count":10,"outputs":[{"output_type":"stream","text":["155 patterns\n","28 tags: ['appreciation', 'chatbots', 'coffeequeriesprice', 'coffeequeriestype', 'delivery', 'deliveryquery', 'funny', 'funnycomment1', 'goodbye', 'greeting', 'introduction1', 'introduction2', 'introduction3', 'introduction4', 'items', 'mood', 'name', 'nod', 'nope', 'ordering1', 'ordering2', 'orderingfail', 'payments', 'roast', 'teaqueriesprice', 'teaqueriestype', 'thanks', 'usermood']\n","121 unique stemmed words: [\"'\", \"'m\", \"'s\", \"'there\", ',', 'a', 'about', 'accept', 'alright', 'am', 'americano', 'an', 'and', 'anyon', 'are', 'bar', 'by', 'bye', 'cafeteria', 'can', 'cappuccino', 'card', 'cash', 'chatbot', 'coffe', 'cool', 'cours', 'credit', 'day', 'deliv', 'deliveri', 'desir', 'do', 'doe', 'doubl', 'earl', 'espresso', 'fine', 'for', 'funni', 'get', 'go', 'good', 'goodby', 'green', 'grey', 'hard', 'have', 'heeeeeeeeeeeeeeeeeeeeey', 'hello', 'help', 'hey', 'hi', 'hola', 'how', 'i', 'is', 'it', 'item', 'job', 'joke', 'kind', 'know', 'larg', 'later', 'latt', 'like', 'long', 'lot', 'mastercard', 'me', 'mean', 'medium', 'mocca', 'much', 'my', 'name', 'no', 'of', 'offer', 'ok', 'onli', 'option', 'pay', 'paypal', 'pleas', 'price', 'purpos', 'roast', 'see', 'sell', 'serv', 'ship', 'small', 'some', 'someth', 'spit', 'sup', 'take', 'tea', 'tell', 'thank', 'that', 'the', 'there', 'thi', 'thing', 'think', 'to', 'today', 'want', 'we', 'what', 'when', 'where', 'with', 'would', 'ye', 'you', 'your', 'yourself']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7s-rOPCaO355","executionInfo":{"status":"ok","timestamp":1610652224492,"user_tz":-60,"elapsed":7613,"user":{"displayName":"Łukasz Pszonak","photoUrl":"","userId":"11546911228613384550"}}},"source":["#Creating the training data \n","#Transforming it into a format that PyTorch Model can understand\n","\n","X_train = []\n","y_train = []\n","for (pattern_sentence, tag) in xy:\n","    # X: bag of words for each pattern_sentence\n","    bag = bag_of_words(pattern_sentence, all_words)\n","    X_train.append(bag)\n","    # y: PyTorch CrossEntropyLoss needs only class labels, not one-hot\n","    #One hot encoding Is the process of splitting multiclass or multi valued data column to separate columns and labelling the cell 1 in the row where it exists.\n","    label = tags.index(tag)\n","    y_train.append(label)\n","\n","X_train = np.array(X_train)\n","y_train = np.array(y_train)\n"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"Nzu2XD-5QhK1","executionInfo":{"status":"ok","timestamp":1610652224492,"user_tz":-60,"elapsed":7610,"user":{"displayName":"Łukasz Pszonak","photoUrl":"","userId":"11546911228613384550"}}},"source":["#Creating the model, It is a feed forward neural Network which will has 3 Linear Layers and is using activation function “ReLU”.\n","#A feedforward neural network is an artificial neural network wherein connections between the nodes do not form a cycle. \n","#As such, it is different from its descendant: recurrent neural networks. The author decided to use FFN instead of RNN because of its simplicity.\n","#As a beginner in Python, too much complexity in the project could easily backfire.\n","\n","class NeuralNet(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_classes):\n","        super(NeuralNet, self).__init__() #I am using super to inherit the properties of its parent class\n","        self.l1 = nn.Linear(input_size, hidden_size) \n","        self.l2 = nn.Linear(hidden_size, hidden_size) \n","        self.l3 = nn.Linear(hidden_size, num_classes)\n","        self.relu = nn.ReLU()\n","\n","#The rectified linear unit, or ReLU function, which is a piece wise linear function that outputs zero if its input is negative, and directly outputs the input otherwise:  \n","    \n","    def forward(self, x):\n","        out = self.l1(x)\n","        out = self.relu(out)\n","        out = self.l2(out)\n","        out = self.relu(out)\n","        out = self.l3(out)\n","        # no activation and no softmax at the end\n","        return out\n","\n","#At this point in the program, a class from NN.Module is inherited.\n","#In the next section its model and layers will be customised."],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"Btm83RGv2Z2s","executionInfo":{"status":"ok","timestamp":1610652224493,"user_tz":-60,"elapsed":7609,"user":{"displayName":"Łukasz Pszonak","photoUrl":"","userId":"11546911228613384550"}}},"source":["#Assigning the Dataset to the Model.\n","\n","class ChatDataset(Dataset):\n","\n","    def __init__(self):\n","        self.n_samples = len(X_train)\n","        self.x_data = X_train\n","        self.y_data = y_train\n","\n","    # support indexing such that dataset[i] can be used to get i-th sample\n","    def __getitem__(self, index):\n","        return self.x_data[index], self.y_data[index]\n","\n","    def __len__(self):\n","        return self.n_samples\n","        "],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4ZWPYYnTO7Cb","executionInfo":{"status":"ok","timestamp":1610652224493,"user_tz":-60,"elapsed":7600,"user":{"displayName":"Łukasz Pszonak","photoUrl":"","userId":"11546911228613384550"}},"outputId":"d6fcb73f-4364-48dc-8a02-2939aba23e54"},"source":["\n","# Hyper-parameters - every Neural Network needs a set of them. They must be set before use.\n","#They were changed many times.\n","num_epochs = 1000 \n","batch_size = 8 \n","learning_rate = 0.001\n","input_size = len(X_train[0])\n","hidden_size = 8 #was 8\n","output_size = len(tags)\n","print(input_size, output_size)"],"execution_count":14,"outputs":[{"output_type":"stream","text":["121 28\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4X5AN0ikPCmR","executionInfo":{"status":"ok","timestamp":1610652224494,"user_tz":-60,"elapsed":7599,"user":{"displayName":"Łukasz Pszonak","photoUrl":"","userId":"11546911228613384550"}}},"source":["#Implementing the model along with loss and optimizer functions\n","\n","dataset = ChatDataset()\n","train_loader = DataLoader(dataset=dataset,\n","                          batch_size=batch_size,\n","                          shuffle=True,\n","                          num_workers=0)\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","model = NeuralNet(input_size, hidden_size, output_size).to(device)\n","\n","#Loss and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6vaFH57TPLe2","executionInfo":{"status":"ok","timestamp":1610652248289,"user_tz":-60,"elapsed":31389,"user":{"displayName":"Łukasz Pszonak","photoUrl":"","userId":"11546911228613384550"}},"outputId":"3acec04c-d6cc-46fa-d451-6e8b82a41d9e"},"source":["#Training the model\n","\n","for epoch in range(num_epochs):\n","    for (words, labels) in train_loader:\n","        words = words.to(device)\n","        labels = labels.to(dtype=torch.long).to(device)\n","        \n","        # Forward pass\n","        outputs = model(words)\n","        \n","        loss = criterion(outputs, labels)\n","        \n","        # Backward and optimize\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        \n","    if (epoch+1) % 100 == 0:\n","        print (f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n","\n","\n","print(f'final loss: {loss.item():.4f}')\n","\n","        \n","\n","data = {\n","\"model_state\": model.state_dict(),\n","\"input_size\": input_size,\n","\"hidden_size\": hidden_size,\n","\"output_size\": output_size,\n","\"all_words\": all_words,\n","\"tags\": tags\n","}"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Epoch [100/1000], Loss: 0.1407\n","Epoch [200/1000], Loss: 0.0280\n","Epoch [300/1000], Loss: 0.0032\n","Epoch [400/1000], Loss: 0.0008\n","Epoch [500/1000], Loss: 0.0005\n","Epoch [600/1000], Loss: 0.0001\n","Epoch [700/1000], Loss: 0.0000\n","Epoch [800/1000], Loss: 0.0001\n","Epoch [900/1000], Loss: 0.0000\n","Epoch [1000/1000], Loss: 0.0000\n","final loss: 0.0000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TIQP3GpfPOm2","executionInfo":{"status":"ok","timestamp":1610652248290,"user_tz":-60,"elapsed":31384,"user":{"displayName":"Łukasz Pszonak","photoUrl":"","userId":"11546911228613384550"}},"outputId":"53c6b4ee-8a4f-4708-f037-ff6ddb1e424d"},"source":["#Saving the trained model\n","\n","FILE = \"data.pth\"\n","torch.save(data, FILE)\n","\n","print(f'training complete. file saved to {FILE}')\n"],"execution_count":17,"outputs":[{"output_type":"stream","text":["training complete. file saved to data.pth\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FX0f_8TgPRqK","executionInfo":{"status":"ok","timestamp":1610652248290,"user_tz":-60,"elapsed":31377,"user":{"displayName":"Łukasz Pszonak","photoUrl":"","userId":"11546911228613384550"}},"outputId":"0eab4e69-cf55-46ea-a908-5ff6aff38654"},"source":["#Loading the saved model\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","with open('intents.json', 'r') as json_data:\n","    intents = json.load(json_data)\n","\n","FILE = \"data.pth\"\n","data = torch.load(FILE)\n","\n","input_size = data[\"input_size\"]\n","hidden_size = data[\"hidden_size\"]\n","output_size = data[\"output_size\"]\n","all_words = data['all_words']\n","tags = data['tags']\n","model_state = data[\"model_state\"]\n","\n","model = NeuralNet(input_size, hidden_size, output_size).to(device)\n","model.load_state_dict(model_state)\n","model.eval()\n"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["NeuralNet(\n","  (l1): Linear(in_features=121, out_features=8, bias=True)\n","  (l2): Linear(in_features=8, out_features=8, bias=True)\n","  (l3): Linear(in_features=8, out_features=28, bias=True)\n","  (relu): ReLU()\n",")"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U_tGgw41THXL","executionInfo":{"status":"ok","timestamp":1610652724229,"user_tz":-60,"elapsed":507308,"user":{"displayName":"Łukasz Pszonak","photoUrl":"","userId":"11546911228613384550"}},"outputId":"08755aa3-6d0d-4d20-9794-f143bab8a279"},"source":["\n","#Using the chatbot\n","#To increase the chatbot's generalized knowledge, it must be trained on a bigger data set.\n","bot_name = \"Cronk\"\n","print(\"Start a chat with Cronk! (type 'quit' to exit)\")\n","while True:\n","    sentence = input(\"You: \")\n","    if sentence == \"quit\":\n","        break\n","\n","    sentence = tokenize(sentence)\n","    X = bag_of_words(sentence, all_words)\n","    X = X.reshape(1, X.shape[0])\n","    X = torch.from_numpy(X).to(device)\n","\n","    output = model(X)\n","    _, predicted = torch.max(output, dim=1)\n","\n","    tag = tags[predicted.item()]\n","\n","    probs = torch.softmax(output, dim=1)\n","    prob = probs[0][predicted.item()]\n","    if prob.item() > 0.75:\n","        for intent in intents['intents']:\n","            if tag == intent[\"tag\"]:\n","                print(f\"{bot_name}: {random.choice(intent['responses'])}\")\n","    else:\n","        print(f\"{bot_name}: I do not understand...\")"],"execution_count":19,"outputs":[{"output_type":"stream","text":["Start a chat with Cronk! (type 'quit' to exit)\n","You: hi\n","Cronk: Hi there, what can I do for you?\n","You: hola\n","Cronk: Hey hi hello!\n","You: hello\n","Cronk: Hi there, how can I help?\n","You: what's going on?\n","Cronk: Yes?\n","You: How are You?\n","Cronk: I do not understand...\n","You: How are you?\n","Cronk: I do not understand...\n","You: How is your day going?\n","Cronk: Yeah, things are good, and You?\n","You: I'm fine, thank You.\n","Cronk: Keep it up!\n","You: What do you do here?\n","Cronk: We have coffee and tea\n","You: I would like a coffee.\n","Cronk: What kind and which capacity? Don't forget to add -please- :)\n","You: Coffee kinds?\n","Cronk: You name it, we got it.\n","You: I would like a small coffee.\n","Cronk: What kind and which capacity? Don't forget to add -please- :)\n","You: Small coffee please.\n","Cronk: Order received, funds deducted from your account. Have a sit.\n","You: Thank You.\n","Cronk: My pleasure\n","You: Tell me about yourself.\n","Cronk: I do not understand...\n","You: Can You tell me something about yourself?\n","Cronk: I am Cronk, the chatbot. I help clients of this great cafeteria with their orders. Do You have any questions?\n","You: What is a chatbot?\n","Cronk: How about You order something?\n","You: What is a chatbot?\n","Cronk: Is that what You want to know in a cafeteria?\n","You: Do You know where we are?\n","Cronk: The cafeteria is on the corner of -Why You asking- and -Not your business Mate-. I work there.\n","You: What do you mean 'there'?\n","Cronk: In the cafeteria system. I am connected to all the booths there. Feel free to order.\n","You: Do You deliver?\n","Cronk: For You or in general? :)\n","You: For me.\n","Cronk: I know. It was a joke. We can deliver.\n","You: Can You tell me a joke?\n","Cronk: Why is 6 afraid of 7? Because 7 8 9 ha ha ha.\n","You: Tell me another joke.\n","Cronk: Are You trying to get roasted? Your whole life is a joke man.\n","You: Tell me one more joke.\n","Cronk: Why did the hipster burn his mouth? He drank the coffee before it was cool.\n","You: Thank You.\n","Cronk: Any time!\n","You: quit\n"],"name":"stdout"}]}]}